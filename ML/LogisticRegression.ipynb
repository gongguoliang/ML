{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = 'E://ggl/sqlResult_1558435.csv'\n",
    "\n",
    "content = pd.read_csv(file, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>xinhua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...</td>\n",
       "      <td>小米MIUI 9首批机型曝光：共计15款</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623597.htm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...</td>\n",
       "      <td>骁龙835在Windows 10上的性能表现有望改善</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623599.htm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...</td>\n",
       "      <td>一加手机5细节曝光：3300mAh、充半小时用1天</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623601.htm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>新华社</td>\n",
       "      <td>这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n</td>\n",
       "      <td>{\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...</td>\n",
       "      <td>葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）</td>\n",
       "      <td>http://world.huanqiu.com/hot/2017-06/10866126....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89613</td>\n",
       "      <td>胡淑丽_MN7479</td>\n",
       "      <td>深圳大件事</td>\n",
       "      <td>（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...</td>\n",
       "      <td>{\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...</td>\n",
       "      <td>44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随</td>\n",
       "      <td>http://news.163.com/17/0618/00/CN617P3Q0001875...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      author                  source  \\\n",
       "0  89617         NaN  快科技@http://www.kkj.cn/   \n",
       "1  89616         NaN  快科技@http://www.kkj.cn/   \n",
       "2  89615         NaN  快科技@http://www.kkj.cn/   \n",
       "3  89614         NaN                     新华社   \n",
       "4  89613  胡淑丽_MN7479                   深圳大件事   \n",
       "\n",
       "                                             content  \\\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...   \n",
       "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...   \n",
       "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...   \n",
       "3    这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n   \n",
       "4  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...   \n",
       "\n",
       "                                             feature  \\\n",
       "0  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...   \n",
       "1  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...   \n",
       "2  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...   \n",
       "3  {\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...   \n",
       "4  {\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...   \n",
       "\n",
       "                           title  \\\n",
       "0           小米MIUI 9首批机型曝光：共计15款   \n",
       "1     骁龙835在Windows 10上的性能表现有望改善   \n",
       "2      一加手机5细节曝光：3300mAh、充半小时用1天   \n",
       "3  葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）   \n",
       "4       44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随   \n",
       "\n",
       "                                                 url  xinhua  \n",
       "0     http://www.cnbeta.com/articles/tech/623597.htm     0.0  \n",
       "1     http://www.cnbeta.com/articles/tech/623599.htm     0.0  \n",
       "2     http://www.cnbeta.com/articles/tech/623601.htm     0.0  \n",
       "3  http://world.huanqiu.com/hot/2017-06/10866126....     1.0  \n",
       "4  http://news.163.com/17/0618/00/CN617P3Q0001875...     0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content['xinhua'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(content)):\n",
    "    if content.iloc[i, 2] == '新华社':\n",
    "        content.loc[i, 'xinhua'] = 1\n",
    "    else:\n",
    "        content.loc[i, 'xinhua'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = content[['content']], content[['xinhua']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       xinhua\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         1.0\n",
      "4         0.0\n",
      "5         0.0\n",
      "6         0.0\n",
      "7         0.0\n",
      "8         0.0\n",
      "9         0.0\n",
      "10        0.0\n",
      "11        0.0\n",
      "12        0.0\n",
      "13        0.0\n",
      "14        0.0\n",
      "15        0.0\n",
      "16        0.0\n",
      "17        0.0\n",
      "18        0.0\n",
      "19        0.0\n",
      "20        0.0\n",
      "21        0.0\n",
      "22        0.0\n",
      "23        0.0\n",
      "24        0.0\n",
      "25        0.0\n",
      "26        0.0\n",
      "27        0.0\n",
      "28        0.0\n",
      "29        0.0\n",
      "...       ...\n",
      "89581     1.0\n",
      "89582     1.0\n",
      "89583     1.0\n",
      "89584     1.0\n",
      "89585     1.0\n",
      "89586     1.0\n",
      "89587     1.0\n",
      "89588     1.0\n",
      "89589     1.0\n",
      "89590     1.0\n",
      "89591     1.0\n",
      "89592     1.0\n",
      "89593     1.0\n",
      "89594     1.0\n",
      "89595     1.0\n",
      "89596     1.0\n",
      "89597     1.0\n",
      "89598     1.0\n",
      "89599     1.0\n",
      "89600     1.0\n",
      "89601     1.0\n",
      "89602     1.0\n",
      "89603     1.0\n",
      "89604     1.0\n",
      "89605     1.0\n",
      "89606     1.0\n",
      "89607     1.0\n",
      "89608     1.0\n",
      "89609     1.0\n",
      "89610     1.0\n",
      "\n",
      "[89611 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\guoli\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.764 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "new_X = []\n",
    "for i in range(len(X)):\n",
    "    tmp = re.sub('[\\\\a-zA-Z0-9，。（）/：…@！？\\s\\n]', '', str(X.iloc[i, 0]))\n",
    "    new_X.append(' '.join(jieba.cut(tmp)))\n",
    "new_X = pd.Series(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外 自 本周 月 日 起 除 小米 手机 等款 机型 外 其余 机型 已 暂停 更新 发布 含 开发 版 体验版 内测 稳定版 暂不受 影响 以 确保 工程师 可以 集中 全部 精力 进行 系统优化 工作 有人 猜测 这 也 是 将 精力 主要 用到 的 研发 之中 去年 月 发布 距今已有 一年 有余 也 是 时候 更新换代 了 当然 关于 的 确切 信息 我们 还是 等待 官方消息'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfVectorizer()\n",
    "X_tfidf = transformer.fit_transform(new_X)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=1988)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_validation, y_train_validation, test_size=0.25, random_state=1988)\n",
    "\n",
    "print(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "model_lg = lg.fit(X_train, y_train)\n",
    "pred_lg = lg.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_validation, pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evoluate(num_py):\n",
    "    acc_lr = (num_py[0][0]+num_py[1][1]) / sum([e for e in sum(num_py)]) * 100\n",
    "    precision_lr = num_py[0][0] / (num_py[0][0]+num_py[0][1]) * 100\n",
    "    recall_lr = num_py[0][0] / (num_py[0][0]+num_py[1][0]) * 100\n",
    "    f1_lr = 2 * precision_lr * recall_lr / (precision_lr+recall_lr)\n",
    "    print('acceracy: ', f'{acc_lr}', '%; ', 'precision: ', f'{precision_lr}', '%;\\n',\n",
    "          'recall: ', f'{recall_lr}', '%.', 'f1 score: ', f'{f1_lr}', sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 96.76375404530745%; precision: 78.15013404825737%;\n",
      "recall: 95.05434782608695%.f1 score: 85.77734183423247\n"
     ]
    }
   ],
   "source": [
    "evoluate(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy is the fraction of correct prediction.\n",
    "- Precision is the the fraction of relevant instances among the retrieved instances.\n",
    "- Recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.\n",
    "- F1 score is the combination of precision and recall.\n",
    "<div align=\"right\">-- https://en.wikipedia.org/wiki/Precision_and_recall</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2: decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_confusiony' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1d2c34d2d1af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpred_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtree_confusion\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mevoluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_confusiony\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tree_confusiony' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "model_dt = dt.fit(X_train, y_train)\n",
    "pred_dt = model_dt.predict(X_validation)\n",
    "tree_confusion= confusion_matrix(y_validation, pred_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 98.93427072871332%; precision: 96.55942806076855%;\n",
      "recall: 94.98901098901099%.f1 score: 95.76778196321737\n"
     ]
    }
   ],
   "source": [
    "evoluate(tree_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3: random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 95.68686530521148%; precision: 70.10723860589813%;\n",
      "recall: 93.78362223550508%.f1 score: 80.23523395551011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "model_rf = rf.fit(X_train, y_train)\n",
    "pred_rf = model_rf.predict(X_validation)\n",
    "evoluate(confusion_matrix(y_validation, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The false negative is much more than decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 4: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 87.51255440241044%; precision: 0.0%;\n",
      "recall: nan%.f1 score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "model_svm = svm.fit(X_train, y_train)\n",
    "pred_svm = model_svm.predict(X_validation)\n",
    "evoluate(confusion_matrix(y_validation, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model (SVM) performs badly. I won't calculate model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Decision Tree outperforms other model. Try to optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2142,    96],\n",
       "       [  113, 15571]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(criterion='entropy')\n",
    "model_dt2 = dt2.fit(X_train, y_train)\n",
    "pred_dt2 = model_dt2.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt2)\n",
    "# a slightly worse than original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9877410007801182%; precision: 0.9486271036315324%;\n",
      "recall: 0.9498891352549889%.f1 score: 0.9492576999778418\n"
     ]
    }
   ],
   "source": [
    "acc_dt2 = (2142+15584) / (2166+96+113+15571)\n",
    "precision_dt2 = 2142 / (2162+96)\n",
    "recall_dt2 = 2142 / (2142+113)\n",
    "f1_dt2 = 2 * precision_dt2 * recall_dt2 / (precision_dt2+recall_dt2)\n",
    "print('acceracy: ', f'{acc_dt2}', '%; ', 'precision: ', f'{precision_dt2}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt2}', '%.', 'f1 score: ', f'{f1_dt2}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune max_dapth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2167,    71],\n",
       "       [  105, 15579]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3 = DecisionTreeClassifier(criterion='gini', max_depth=10)\n",
    "model_dt3 = dt3.fit(X_train, y_train)\n",
    "pred_dt3 = model_dt3.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9901796674478295%; precision: 0.9704433497536946%;\n",
      "recall: 0.9537852112676056%.f1 score: 0.9620421753607102\n"
     ]
    }
   ],
   "source": [
    "acc_dt3 = (2167+15579) / (2167+71+105+15579)\n",
    "precision_dt3 = 2167 / (2167+66)\n",
    "recall_dt3 = 2167 / (2167+105)\n",
    "f1_dt3 = 2 * precision_dt3 * recall_dt3 / (precision_dt3+recall_dt3)\n",
    "print('acceracy: ', f'{acc_dt3}', '%; ', 'precision: ', f'{precision_dt3}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt3}', '%.', 'f1 score: ', f'{f1_dt3}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third model performs best. Tune min_samples_leaf based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2167,    71],\n",
       "       [  108, 15576]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt4 = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=2)\n",
    "model_dt4 = dt4.fit(X_train, y_train)\n",
    "pred_dt4 = model_dt4.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9900122754156903%; precision: 0.9682752457551386%;\n",
      "recall: 0.9525274725274725%.f1 score: 0.9603368047861732\n"
     ]
    }
   ],
   "source": [
    "acc_dt3 = (2167+15576) / (2167+71+108+15576)\n",
    "precision_dt3 = 2167 / (2167+71)\n",
    "recall_dt3 = 2167 / (2167+108)\n",
    "f1_dt3 = 2 * precision_dt3 * recall_dt3 / (precision_dt3+recall_dt3)\n",
    "print('acceracy: ', f'{acc_dt3}', '%; ', 'precision: ', f'{precision_dt3}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt3}', '%.', 'f1 score: ', f'{f1_dt3}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third model still performs best. Next tune min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2168,    70],\n",
       "       [  105, 15579]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt5 = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_split=3)\n",
    "model_dt5 = dt5.fit(X_train, y_train)\n",
    "pred_dt5 = model_dt5.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9903470594799687%; precision: 0.968722073279714%;\n",
      "recall: 0.9538055433347998%.f1 score: 0.9612059410330304\n"
     ]
    }
   ],
   "source": [
    "acc_dt5 = (2168+15581) / (2168+70+105+15579)\n",
    "precision_dt5 = 2168 / (2168+70)\n",
    "recall_dt5 = 2168 / (2168+105)\n",
    "f1_dt5 = 2 * precision_dt5 * recall_dt5 / (precision_dt5+recall_dt5)\n",
    "print('acceracy: ', f'{acc_dt5}', '%; ', 'precision: ', f'{precision_dt5}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt5}', '%.', 'f1 score: ', f'{f1_dt5}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still the third model preforms best. Last to tune min_weight_fraction_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 97.63419261243165%; precision: 91.24218051831993%;\n",
      "recall: 89.95594713656388%.f1 score: 90.59449866903283\n"
     ]
    }
   ],
   "source": [
    "dt6 = DecisionTreeClassifier(criterion='gini', max_depth=10, min_weight_fraction_leaf=0.01)\n",
    "model_dt6 = dt6.fit(X_train, y_train)\n",
    "pred_dt6 = model_dt6.predict(X_validation)\n",
    "evoluate(confusion_matrix(y_validation, pred_dt6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy significantly decrease. This model won't be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The conclusion is model 3 outperforms other models. Will use it to detect plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## split the dataset without TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only X_test_contest is useful, I don't care others.\n",
    "X_train_validation_contest, X_test_contest, y_train_validation, y_test = train_test_split(new_X, y, test_size=0.2, random_state=1988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dt_best = dt3.fit(X_train_validation, y_train_validation) # use a larger dataset\n",
    "predict = model_dt_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = pd.Series(predict, index=X_test_contest.index)\n",
    "articles = pd.DataFrame({'articles':X_test_contest, 'citation':y_test, 'predict':predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plagiarism = articles.loc[(articles['citation']==0) & (articles['predict']==1)]\n",
    "# https://stackoverflow.com/questions/13611065/efficient-way-to-apply-multiple-filters-to-pandas-dataframe-or-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plagiarism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The conclusion is that there is no plagiarism!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
